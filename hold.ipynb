{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3d8437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 | AUC: 0.818 | F1: 0.727 | BalAcc: 0.697\n",
      "Fold 2 | AUC: 0.747 | F1: 0.762 | BalAcc: 0.753\n",
      "Fold 3 | AUC: 0.616 | F1: 0.353 | BalAcc: 0.470\n",
      "Fold 4 | AUC: 0.727 | F1: 0.636 | BalAcc: 0.596\n",
      "Fold 5 | AUC: 0.808 | F1: 0.750 | BalAcc: 0.687\n",
      "\n",
      "--- 5-Split 80/20 Holdout Performance ---\n",
      "AUC: 0.743 ± 0.072\n",
      "Accuracy: 0.640 ± 0.107\n",
      "F1: 0.646 ± 0.153\n",
      "Precision: 0.671 ± 0.101\n",
      "Recall: 0.636 ± 0.191\n",
      "BalancedAcc: 0.640 ± 0.099\n",
      "\n",
      "--- Feature Importances ---\n",
      "Feature_Theta_Global_Abs             0.262712\n",
      "Feature_Theta_Asymmetry_Idx          0.208826\n",
      "Feature_Sync_Delta_ClassA_Frontal    0.206298\n",
      "Feature_HubPLI_Beta_Delta            0.174051\n",
      "Feature_DeltaBeta_Global             0.148114\n",
      "dtype: float64\n",
      "\n",
      "Final model saved as PD_MoCA_RF_5Feature_Final.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, f1_score,\n",
    "                             precision_score, recall_score, balanced_accuracy_score)\n",
    "import joblib\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\Documents\\EEG_Project\\dataSheets\\ML_Feature_Matrix.csv\")\n",
    "\n",
    "# =========================\n",
    "# SELECTED FEATURES\n",
    "# =========================\n",
    "FEATURES = [\n",
    "    'Feature_Sync_Delta_ClassA_Frontal',\n",
    "    'Feature_Theta_Global_Abs',\n",
    "    'Feature_HubPLI_Beta_Delta',\n",
    "    'Feature_DeltaBeta_Global',\n",
    "    'Feature_Theta_Asymmetry_Idx',\n",
    "]\n",
    "\n",
    "X = df[FEATURES].values\n",
    "y = df['Label_Impaired'].values\n",
    "\n",
    "# =========================\n",
    "# 5 x 80/20 STRATIFIED SPLITS\n",
    "# =========================\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=4224)\n",
    "\n",
    "results = {\n",
    "    'AUC': [], 'Accuracy': [], 'F1': [],\n",
    "    'Precision': [], 'Recall': [], 'BalancedAcc': []\n",
    "}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(sss.split(X, y)):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', RandomForestClassifier(\n",
    "            n_estimators=500,\n",
    "            random_state=4224,\n",
    "            max_depth=5\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    results['AUC'].append(roc_auc_score(y_test, y_prob))\n",
    "    results['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    results['F1'].append(f1_score(y_test, y_pred))\n",
    "    results['Precision'].append(precision_score(y_test, y_pred))\n",
    "    results['Recall'].append(recall_score(y_test, y_pred))\n",
    "    results['BalancedAcc'].append(balanced_accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(f\"Fold {fold+1} | AUC: {results['AUC'][-1]:.3f} | \"\n",
    "          f\"F1: {results['F1'][-1]:.3f} | \"\n",
    "          f\"BalAcc: {results['BalancedAcc'][-1]:.3f}\")\n",
    "\n",
    "# =========================\n",
    "# SUMMARY\n",
    "# =========================\n",
    "print(\"\\n--- 5-Split 80/20 Holdout Performance ---\")\n",
    "for metric, scores in results.items():\n",
    "    print(f\"{metric}: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "# =========================\n",
    "# TRAIN FINAL MODEL ON FULL DATA\n",
    "# =========================\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        random_state=4224,\n",
    "        max_depth=5\n",
    "    ))\n",
    "])\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# =========================\n",
    "# FEATURE IMPORTANCE\n",
    "# =========================\n",
    "rf_model = final_pipeline.named_steps['rf']\n",
    "importances = pd.Series(rf_model.feature_importances_, index=FEATURES).sort_values(ascending=False)\n",
    "print(\"\\n--- Feature Importances ---\")\n",
    "print(importances)\n",
    "\n",
    "# =========================\n",
    "# SAVE MODEL\n",
    "# =========================\n",
    "# joblib.dump(final_pipeline, \"PD_MoCA_RF_5Feature_Final.pkl\")\n",
    "print(\"\\nFinal model saved as PD_MoCA_RF_5Feature_Final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f78f09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 | AUC: 0.879 | F1: 0.857 | BalAcc: 0.854\n",
      "Fold 2 | AUC: 0.677 | F1: 0.667 | BalAcc: 0.717\n",
      "Fold 3 | AUC: 0.929 | F1: 0.846 | BalAcc: 0.778\n",
      "Fold 4 | AUC: 0.820 | F1: 0.667 | BalAcc: 0.700\n",
      "Fold 5 | AUC: 0.780 | F1: 0.700 | BalAcc: 0.700\n",
      "Fold 6 | AUC: 0.889 | F1: 0.786 | BalAcc: 0.667\n",
      "Fold 7 | AUC: 0.828 | F1: 0.762 | BalAcc: 0.753\n",
      "Fold 8 | AUC: 0.768 | F1: 0.667 | BalAcc: 0.652\n",
      "Fold 9 | AUC: 0.820 | F1: 0.750 | BalAcc: 0.800\n",
      "Fold 10 | AUC: 0.810 | F1: 0.783 | BalAcc: 0.750\n",
      "Fold 11 | AUC: 0.566 | F1: 0.588 | BalAcc: 0.672\n",
      "Fold 12 | AUC: 0.909 | F1: 0.769 | BalAcc: 0.677\n",
      "Fold 13 | AUC: 0.646 | F1: 0.696 | BalAcc: 0.641\n",
      "Fold 14 | AUC: 0.810 | F1: 0.700 | BalAcc: 0.700\n",
      "Fold 15 | AUC: 0.830 | F1: 0.667 | BalAcc: 0.700\n",
      "Fold 16 | AUC: 0.899 | F1: 0.818 | BalAcc: 0.798\n",
      "Fold 17 | AUC: 0.949 | F1: 0.870 | BalAcc: 0.843\n",
      "Fold 18 | AUC: 0.707 | F1: 0.696 | BalAcc: 0.641\n",
      "Fold 19 | AUC: 0.690 | F1: 0.667 | BalAcc: 0.650\n",
      "Fold 20 | AUC: 0.760 | F1: 0.588 | BalAcc: 0.650\n",
      "Fold 21 | AUC: 0.889 | F1: 0.800 | BalAcc: 0.732\n",
      "Fold 22 | AUC: 0.768 | F1: 0.783 | BalAcc: 0.742\n",
      "Fold 23 | AUC: 0.838 | F1: 0.737 | BalAcc: 0.763\n",
      "Fold 24 | AUC: 0.870 | F1: 0.762 | BalAcc: 0.750\n",
      "Fold 25 | AUC: 0.760 | F1: 0.700 | BalAcc: 0.700\n",
      "AUC: 0.804 ± 0.092\n",
      "Accuracy: 0.724 ± 0.060\n",
      "F1: 0.733 ± 0.075\n",
      "Precision: 0.753 ± 0.088\n",
      "Recall: 0.737 ± 0.146\n",
      "BalancedAcc: 0.721 ± 0.060\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# 5-fold CV, repeated 5 times -> 25 evaluations total\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=4224)\n",
    "\n",
    "results = {k: [] for k in ['AUC', 'Accuracy', 'F1', 'Precision', 'Recall', 'BalancedAcc']}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', RandomForestClassifier(n_estimators=500, max_depth=5, random_state=4224))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    results['AUC'].append(roc_auc_score(y_test, y_prob))\n",
    "    results['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    results['F1'].append(f1_score(y_test, y_pred))\n",
    "    results['Precision'].append(precision_score(y_test, y_pred))\n",
    "    results['Recall'].append(recall_score(y_test, y_pred))\n",
    "    results['BalancedAcc'].append(balanced_accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(f\"Fold {fold+1} | AUC: {results['AUC'][-1]:.3f} | \"\n",
    "          f\"F1: {results['F1'][-1]:.3f} | \"\n",
    "          f\"BalAcc: {results['BalancedAcc'][-1]:.3f}\")\n",
    "\n",
    "# Summary\n",
    "for metric, scores in results.items():\n",
    "    print(f\"{metric}: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a147e58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.804 ± 0.092\n",
      "Accuracy: 0.724 ± 0.060\n",
      "F1: 0.733 ± 0.075\n",
      "Precision: 0.753 ± 0.088\n",
      "Recall: 0.737 ± 0.146\n",
      "BalancedAcc: 0.721 ± 0.060\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Define your pipeline once\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=500, max_depth=5, random_state=4224))\n",
    "])\n",
    "\n",
    "# Define the metrics you want\n",
    "scoring = {\n",
    "    'AUC': 'roc_auc',\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': 'f1',\n",
    "    'Precision': 'precision',\n",
    "    'Recall': 'recall',\n",
    "    'BalancedAcc': 'balanced_accuracy'\n",
    "}\n",
    "\n",
    "# Run everything in one go\n",
    "cv_results = cross_validate(pipeline, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "# Summary logic\n",
    "for metric in scoring.keys():\n",
    "    test_metric = f'test_{metric}'\n",
    "    print(f\"{metric}: {cv_results[test_metric].mean():.3f} ± {cv_results[test_metric].std():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
