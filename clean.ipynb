{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda14ef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      8\u001b[39m RANDOM_STATE = \u001b[32m42\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 1. DATA SPLITTING — 80/20, Test Set Locked Away\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     13\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     X, y,\n\u001b[32m     15\u001b[39m     test_size=\u001b[32m0.20\u001b[39m,\n\u001b[32m     16\u001b[39m     stratify=y,\n\u001b[32m     17\u001b[39m     random_state=RANDOM_STATE\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mData Split: Train=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Test=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# 2. FORWARD FEATURE SELECTION (CV on Train only)\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Uses 5-fold stratified CV instead of a single val set\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# — much more stable estimates, no data wasted\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ============================================================\n",
    "# 1. DATA SPLITTING — 80/20, Test Set Locked Away\n",
    "# ============================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"Data Split: Train={len(X_train)} | Test={len(X_test)}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. FORWARD FEATURE SELECTION (CV on Train only)\n",
    "# Uses 5-fold stratified CV instead of a single val set\n",
    "# — much more stable estimates, no data wasted\n",
    "# ============================================================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "selected_idx = []\n",
    "remaining_idx = list(range(X.shape[1]))\n",
    "best_auc = 0.0\n",
    "\n",
    "print(\"\\n--- Running Forward Selection (5-Fold CV) ---\")\n",
    "\n",
    "for step in range(MAX_FEATURES):\n",
    "    step_results = []\n",
    "\n",
    "    for i in remaining_idx:\n",
    "        trial_idx = selected_idx + [i]\n",
    "\n",
    "        # Pipeline handles scaler + model inside each CV fold — no leakage\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", RandomForestClassifier(\n",
    "                n_estimators=300,\n",
    "                max_depth=5,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            pipe,\n",
    "            X_train[:, trial_idx],\n",
    "            y_train,\n",
    "            cv=cv,\n",
    "            scoring=\"roc_auc\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        step_results.append((i, scores.mean()))\n",
    "\n",
    "    best_i, best_step_auc = max(step_results, key=lambda x: x[1])\n",
    "\n",
    "    if best_step_auc <= best_auc + 1e-4:\n",
    "        print(\"No further improvement — stopping.\")\n",
    "        break\n",
    "\n",
    "    selected_idx.append(best_i)\n",
    "    remaining_idx.remove(best_i)\n",
    "    best_auc = best_step_auc\n",
    "    print(f\"Step {step+1}: Added '{FEATURES[best_i]}' | CV AUC: {best_auc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. FINAL MODEL — Retrain on ALL train data, evaluate on test\n",
    "# ============================================================\n",
    "pipe_final = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe_final.fit(X_train[:, selected_idx], y_train)\n",
    "\n",
    "final_probs = pipe_final.predict_proba(X_test[:, selected_idx])[:, 1]\n",
    "final_preds = pipe_final.predict(X_test[:, selected_idx])\n",
    "\n",
    "auc = roc_auc_score(y_test, final_probs)\n",
    "acc = accuracy_score(y_test, final_preds)\n",
    "f1  = f1_score(y_test, final_preds)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 45)\n",
    "print(f\"SELECTED FEATURES : {FEATURES[selected_idx].tolist()}\")\n",
    "print(f\"TEST AUC          : {auc:.4f}\")\n",
    "print(f\"TEST ACCURACY     : {acc:.4f}\")\n",
    "print(f\"TEST F1           : {f1:.4f}\")\n",
    "print(\"=\" * 45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
