{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8efbcdef",
   "metadata": {},
   "source": [
    "### DONT TOUCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fa08a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final 6-Feature Model CV Performance ---\n",
      "test_AUC: 0.767 ± 0.099\n",
      "test_Accuracy: 0.730 ± 0.040\n",
      "test_F1: 0.732 ± 0.063\n",
      "test_Precision: 0.769 ± 0.063\n",
      "test_Recall: 0.715 ± 0.113\n",
      "test_BalancedAcc: 0.729 ± 0.040\n",
      "\n",
      "--- Detailed Feature Importances ---\n",
      "                                   Gini_Importance  Gini_Std  \\\n",
      "Feature_Theta_Global_Abs                  0.250456  0.181750   \n",
      "Feature_Theta_Asymmetry_Idx               0.199631  0.153365   \n",
      "Feature_HubPLI_Beta_Delta                 0.151082  0.124445   \n",
      "Feature_Sync_Delta_ClassA_Frontal         0.178227  0.158656   \n",
      "Feature_DeltaBeta_Global                  0.135197  0.127653   \n",
      "Feature_Instab_Theta_duration_Var         0.085407  0.096514   \n",
      "\n",
      "                                   Permutation_Mean  Permutation_Std  \n",
      "Feature_Theta_Global_Abs                      0.141         0.024678  \n",
      "Feature_Theta_Asymmetry_Idx                   0.113         0.031953  \n",
      "Feature_HubPLI_Beta_Delta                     0.105         0.023345  \n",
      "Feature_Sync_Delta_ClassA_Frontal             0.089         0.027000  \n",
      "Feature_DeltaBeta_Global                      0.060         0.019494  \n",
      "Feature_Instab_Theta_duration_Var             0.043         0.012689  \n",
      "\n",
      "Final model training complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\Documents\\EEG_Project\\dataSheets\\ML_Feature_Matrix.csv\")\n",
    "\n",
    "# Check for NaNs (Best practice for EEG datasets)\n",
    "if df.isnull().values.any():\n",
    "    print(\"Warning: NaNs detected. Dropping rows with missing values.\")\n",
    "    df = df.dropna()\n",
    "\n",
    "FEATURES = [\n",
    "    'Feature_Sync_Delta_ClassA_Frontal',\n",
    "    'Feature_Theta_Global_Abs',\n",
    "    'Feature_HubPLI_Beta_Delta',\n",
    "    'Feature_DeltaBeta_Global',\n",
    "    'Feature_Theta_Asymmetry_Idx',\n",
    "    'Feature_Instab_Theta_duration_Var'\n",
    "]\n",
    "\n",
    "X = df[FEATURES].values\n",
    "y = df['Label_Impaired'].values\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring_metrics = {\n",
    "    'AUC': 'roc_auc',\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': make_scorer(f1_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'BalancedAcc': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# BUILD FINAL MODEL PIPELINE\n",
    "# =========================\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=800,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=4,\n",
    "        min_samples_split=8,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# CROSS-VALIDATED EVALUATION\n",
    "# =========================\n",
    "cv_results = cross_validate(final_pipeline, X, y, cv=cv, scoring=scoring_metrics, return_train_score=False)\n",
    "\n",
    "print(\"\\n--- Final 6-Feature Model CV Performance ---\")\n",
    "for metric_name, scores in cv_results.items():\n",
    "    if metric_name.startswith('test_'):\n",
    "        print(f\"{metric_name}: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "# =========================\n",
    "# TRAIN FINAL MODEL ON FULL DATA\n",
    "# =========================\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# =========================\n",
    "# ADVANCED FEATURE IMPORTANCE\n",
    "# =========================\n",
    "rf_model = final_pipeline.named_steps['rf']\n",
    "\n",
    "# 1. Gini Importance with Variance\n",
    "importances_mean = rf_model.feature_importances_\n",
    "importances_std = np.std([tree.feature_importances_ for tree in rf_model.estimators_], axis=0)\n",
    "\n",
    "# 2. Permutation Importance (More reliable)\n",
    "# This measures how much the model performance drops when a feature is shuffled\n",
    "perm_res = permutation_importance(final_pipeline, X, y, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Gini_Importance': importances_mean,\n",
    "    'Gini_Std': importances_std,\n",
    "    'Permutation_Mean': perm_res.importances_mean,\n",
    "    'Permutation_Std': perm_res.importances_std\n",
    "}, index=FEATURES).sort_values(by='Permutation_Mean', ascending=False)\n",
    "\n",
    "print(\"\\n--- Detailed Feature Importances ---\")\n",
    "print(importance_df)\n",
    "\n",
    "# =========================\n",
    "# SAVE MODEL\n",
    "# =========================\n",
    "# joblib.dump(final_pipeline, \"PD_MoCA_RF_6Feature_Final.pkl\")\n",
    "print(\"\\nFinal model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8bccdc",
   "metadata": {},
   "source": [
    "### DONT TOUCH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d18a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final 5-Feature Model Repeated CV Performance ---\n",
      "AUC: 0.767 ± 0.088\n",
      "Accuracy: 0.740 ± 0.087\n",
      "F1: 0.749 ± 0.086\n",
      "Precision: 0.768 ± 0.097\n",
      "Recall: 0.743 ± 0.117\n",
      "BalancedAcc: 0.737 ± 0.089\n",
      "\n",
      "--- Feature Importances ---\n",
      "Feature_Theta_Asymmetry_Idx    0.200401\n",
      "Feature_Theta_Global_Abs       0.199450\n",
      "Feature_ThetaAlpha_Global      0.168162\n",
      "Feature_HubPLI_Beta_Frontal    0.155497\n",
      "Feature_HubPLI_Beta_Delta      0.147449\n",
      "Feature_DeltaBeta_Global       0.129042\n",
      "dtype: float64\n",
      "\n",
      "Final model saved as PD_MoCA_RF_5Feature_Final.pkl\n",
      "Individual Fold AUCs: [0.80808081 0.88888889 0.65656566 0.67       0.72       0.86868687\n",
      " 0.62626263 0.62626263 0.88       0.84       0.81818182 0.85858586\n",
      " 0.83838384 0.74       0.7        0.80808081 0.67676768 0.7979798\n",
      " 0.84       0.68      ]\n",
      "Individual Fold Accs: [0.8  0.8  0.65 0.75 0.65 0.8  0.65 0.6  0.9  0.65 0.8  0.8  0.85 0.75\n",
      " 0.65 0.85 0.6  0.75 0.8  0.7 ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import joblib\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "df = pd.read_csv(\"ML_Feature_Matrix.csv\")\n",
    "\n",
    "# =========================\n",
    "# SELECTED FEATURES (5 best)\n",
    "# =========================\n",
    "FEATURES = [\n",
    "    #'Feature_Sync_Delta_ClassA_Frontal',\n",
    "    'Feature_Theta_Global_Abs',\n",
    "    'Feature_HubPLI_Beta_Delta',\n",
    "    'Feature_HubPLI_Beta_Frontal',\n",
    "    'Feature_DeltaBeta_Global',\n",
    "    'Feature_Theta_Asymmetry_Idx',\n",
    "    'Feature_ThetaAlpha_Global'\n",
    "\n",
    "]\n",
    "\n",
    "X = df[FEATURES].values\n",
    "y = df['Label_Impaired'].values\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=4, random_state=321)  # Repeated 5x5 CV\n",
    "\n",
    "scoring_metrics = {\n",
    "    'AUC': 'roc_auc',\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': make_scorer(f1_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'BalancedAcc': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# FINAL MODEL PIPELINE\n",
    "# =========================\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # optional for RF\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        random_state=42,\n",
    "        max_depth=10\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# CROSS-VALIDATED EVALUATION\n",
    "# =========================\n",
    "cv_results = cross_validate(final_pipeline, X, y, cv=cv, scoring=scoring_metrics, return_train_score=False)\n",
    "\n",
    "print(\"\\n--- Final 5-Feature Model Repeated CV Performance ---\")\n",
    "for metric_name, scores in cv_results.items():\n",
    "    if metric_name.startswith('test_'):\n",
    "        print(f\"{metric_name[5:]}: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "# =========================\n",
    "# TRAIN FINAL MODEL ON FULL DATA\n",
    "# =========================\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# =========================\n",
    "# FEATURE IMPORTANCE\n",
    "# =========================\n",
    "rf_model = final_pipeline.named_steps['rf']\n",
    "importances = pd.Series(rf_model.feature_importances_, index=FEATURES).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n--- Feature Importances ---\")\n",
    "print(importances)\n",
    "\n",
    "# =========================\n",
    "# SAVE MODEL\n",
    "# =========================\n",
    "#joblib.dump(final_pipeline, \"PD_MoCA_RF_5Feature_Final.pkl\")\n",
    "print(\"\\nFinal model saved as PD_MoCA_RF_5Feature_Final.pkl\")\n",
    "\n",
    "# Individual fold scores\n",
    "print(f\"Individual Fold AUCs: {cv_results['test_AUC']}\")\n",
    "print(f\"Individual Fold Accs: {cv_results['test_Accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d5b46a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final 5-Feature Model CV Performance ---\n",
      "AUC: 0.783 ± 0.136\n",
      "Accuracy: 0.750 ± 0.100\n",
      "F1: 0.757 ± 0.115\n",
      "Precision: 0.772 ± 0.132\n",
      "Recall: 0.751 ± 0.126\n",
      "BalancedAcc: 0.750 ± 0.103\n",
      "\n",
      "--- Feature Importances ---\n",
      "Feature_Theta_Global_Abs             0.214786\n",
      "Feature_Theta_Asymmetry_Idx          0.195194\n",
      "Feature_ThetaAlpha_Global            0.165182\n",
      "Feature_Sync_Delta_ClassA_Frontal    0.159197\n",
      "Feature_HubPLI_Beta_Delta            0.148849\n",
      "Feature_DeltaBeta_Global             0.116792\n",
      "dtype: float64\n",
      "\n",
      "Final model saved as PD_MoCA_RF_5Feature_Final.pkl\n",
      "Individual Fold AUCs: [0.6969697  0.8989899  0.83838384 0.56       0.92      ]\n",
      "Maximum (Peak) AUC: 0.920\n",
      "Individual Fold Accs: [0.75 0.8  0.9  0.6  0.7 ]\n",
      "Maximum (Peak) Acc: 0.900\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import joblib\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "df = pd.read_csv(\"ML_Feature_Matrix.csv\")\n",
    "\n",
    "# =========================\n",
    "# SELECTED FEATURES (5 best)\n",
    "# =========================\n",
    "FEATURES = [\n",
    "    'Feature_Sync_Delta_ClassA_Frontal',\n",
    "    'Feature_Theta_Global_Abs',\n",
    "    'Feature_HubPLI_Beta_Delta',\n",
    "    'Feature_DeltaBeta_Global',\n",
    "    'Feature_Theta_Asymmetry_Idx',\n",
    "    'Feature_ThetaAlpha_Global'\n",
    "\n",
    "]\n",
    "\n",
    "X = df[FEATURES].values\n",
    "y = df['Label_Impaired'].values\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring_metrics = {\n",
    "    'AUC': 'roc_auc',\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': make_scorer(f1_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'BalancedAcc': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# FINAL MODEL PIPELINE\n",
    "# =========================\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # optional for RF\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=800,\n",
    "        random_state=42,\n",
    "        max_depth=5,\n",
    "        class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# CROSS-VALIDATED EVALUATION\n",
    "# =========================\n",
    "cv_results = cross_validate(final_pipeline, X, y, cv=cv, scoring=scoring_metrics, return_train_score=False)\n",
    "\n",
    "print(\"\\n--- Final 5-Feature Model CV Performance ---\")\n",
    "for metric_name, scores in cv_results.items():\n",
    "    if metric_name.startswith('test_'):\n",
    "        print(f\"{metric_name[5:]}: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "# =========================\n",
    "# TRAIN FINAL MODEL ON FULL DATA\n",
    "# =========================\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# =========================\n",
    "# FEATURE IMPORTANCE\n",
    "# =========================\n",
    "rf_model = final_pipeline.named_steps['rf']\n",
    "importances = pd.Series(rf_model.feature_importances_, index=FEATURES).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n--- Feature Importances ---\")\n",
    "print(importances)\n",
    "\n",
    "# =========================\n",
    "# SAVE MODEL\n",
    "# =========================\n",
    "joblib.dump(final_pipeline, \"PD_MoCA_RF_5Feature_Final.pkl\")\n",
    "print(\"\\nFinal model saved as PD_MoCA_RF_5Feature_Final.pkl\")\n",
    "\n",
    "\n",
    "# Add this line after your print loop to see the individual fold scores\n",
    "print(f\"Individual Fold AUCs: {cv_results['test_AUC']}\")\n",
    "print(f\"Maximum (Peak) AUC: {np.max(cv_results['test_AUC']):.3f}\")\n",
    "\n",
    "print(f\"Individual Fold Accs: {cv_results['test_Accuracy']}\")\n",
    "print(f\"Maximum (Peak) Acc: {np.max(cv_results['test_Accuracy']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49086a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11b06541",
   "metadata": {},
   "source": [
    "### Hyper Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba703f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, ConfusionMatrixDisplay\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#RANDOM STATE 3\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Split data into training and test sets\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[32m      7\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     df[FEATURES], df[\u001b[33m'\u001b[39m\u001b[33mLabel_Impaired\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m      9\u001b[39m     test_size=\u001b[32m0.25\u001b[39m, stratify=df[\u001b[33m'\u001b[39m\u001b[33mLabel_Impaired\u001b[39m\u001b[33m'\u001b[39m], random_state=\u001b[32m000\u001b[39m\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Train final pipeline on training set\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[32m     15\u001b[39m final_pipeline.fit(X_train, y_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "#RANDOM STATE 3\n",
    "# =========================\n",
    "# Split data into training and test sets\n",
    "# =========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[FEATURES], df['Label_Impaired'], \n",
    "    test_size=0.25, stratify=df['Label_Impaired'], random_state=000\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Train final pipeline on training set\n",
    "# =========================\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# =========================\n",
    "# Get predictions on test set\n",
    "# =========================\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "\n",
    "# =========================\n",
    "# Compute confusion matrix\n",
    "# =========================\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=['Unimpaired', 'Impaired'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "disp.ax_.set_title(\"Confusion Matrix - Random Forest on Test Set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d7a98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFECV Robust AUC: 0.721 ± 0.103\n",
      "\n",
      "--- Feature Selection Frequency ---\n",
      "Feature_Sync_Delta_ClassA_Frontal: Selected in 15/50 folds\n",
      "Feature_Theta_Global_Abs: Selected in 18/50 folds\n",
      "Feature_HubPLI_Beta_Delta: Selected in 48/50 folds\n",
      "Feature_DeltaBeta_Global: Selected in 21/50 folds\n",
      "Feature_Theta_Asymmetry_Idx: Selected in 50/50 folds\n",
      "Feature_ThetaAlpha_Global: Selected in 50/50 folds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# 1. DEFINE SELECTOR (Linear SVM is best for RFE coefficients)\n",
    "selector_model = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "\n",
    "# 2. RFECV PIPELINE\n",
    "# min_features_to_select=3 prevents the model from dropping too many clinical markers\n",
    "rfecv = RFECV(\n",
    "    estimator=selector_model,\n",
    "    step=1,\n",
    "    cv=StratifiedKFold(5), \n",
    "    scoring='roc_auc',\n",
    "    min_features_to_select=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 3. FULL PIPELINE: Scale -> RFECV -> Final SVM\n",
    "robust_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selection', rfecv),\n",
    "    ('svm', SVC(probability=True, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# 4. ROBUST EVALUATION (Repeated Nested CV)\n",
    "cv_robust = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "cv_results = cross_validate(\n",
    "    robust_pipeline, X, y, \n",
    "    cv=cv_robust, \n",
    "    scoring=scoring_metrics, \n",
    "    n_jobs=-1,\n",
    "    return_estimator=True\n",
    ")\n",
    "\n",
    "# 5. PRINT RESULTS\n",
    "print(f\"RFECV Robust AUC: {np.mean(cv_results['test_AUC']):.3f} ± {np.std(cv_results['test_AUC']):.3f}\")\n",
    "\n",
    "# 6. IDENTIFY CONSENSUS FEATURES\n",
    "# Check which features were selected most often across the 50 folds\n",
    "feature_support = np.array([est.named_steps['feature_selection'].support_ for est in cv_results['estimator']])\n",
    "print(\"\\n--- Feature Selection Frequency ---\")\n",
    "for feat, count in zip(FEATURES, feature_support.sum(axis=0)):\n",
    "    print(f\"{feat}: Selected in {count}/50 folds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006363ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF-RFECV Robust AUC: 0.778 ± 0.081\n",
      "\n",
      "--- Random Forest Feature Selection Frequency ---\n",
      "Feature_Sync_Delta_ClassA_Frontal: Selected in 49/50 folds\n",
      "Feature_Theta_Global_Abs: Selected in 50/50 folds\n",
      "Feature_HubPLI_Beta_Delta: Selected in 43/50 folds\n",
      "Feature_DeltaBeta_Global: Selected in 41/50 folds\n",
      "Feature_Theta_Asymmetry_Idx: Selected in 50/50 folds\n",
      "Feature_ThetaAlpha_Global: Selected in 49/50 folds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "df = pd.read_csv(\"ML_Feature_Matrix.csv\")\n",
    "FEATURES = [\n",
    "    'Feature_Sync_Delta_ClassA_Frontal',\n",
    "    'Feature_Theta_Global_Abs',\n",
    "    'Feature_HubPLI_Beta_Delta',\n",
    "    'Feature_DeltaBeta_Global',\n",
    "    'Feature_Theta_Asymmetry_Idx'\n",
    "]\n",
    "X = df[FEATURES].values\n",
    "y = df['Label_Impaired'].values\n",
    "\n",
    "# =========================\n",
    "# SCORING METRICS\n",
    "# =========================\n",
    "scoring_metrics = {\n",
    "    'AUC': 'roc_auc',\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': make_scorer(f1_score),\n",
    "    'Precision': make_scorer(precision_score, zero_division=0),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'BalancedAcc': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# RFECV Selector\n",
    "# =========================\n",
    "selector_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=selector_rf,\n",
    "    step=1,\n",
    "    cv=StratifiedKFold(5, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    min_features_to_select=3,\n",
    "    n_jobs=1  # safe on Windows\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# FULL PIPELINE\n",
    "# =========================\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selection', rfecv),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# REPEATED CV\n",
    "# =========================\n",
    "cv_robust = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    rf_pipeline, X, y,\n",
    "    cv=cv_robust,\n",
    "    scoring=scoring_metrics,\n",
    "    n_jobs=1,  # prevent nested parallelism crash\n",
    "    return_estimator=True\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# REPORT METRICS\n",
    "# =========================\n",
    "print(\"\\n--- RF-RFECV Robust CV Performance ---\")\n",
    "for metric in scoring_metrics.keys():\n",
    "    scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric}: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "# =========================\n",
    "# FEATURE STABILITY\n",
    "# =========================\n",
    "feature_support = np.array([est.named_steps['feature_selection'].support_ for est in cv_results['estimator']])\n",
    "print(\"\\n--- Random Forest Feature Selection Frequency ---\")\n",
    "for feat, count in zip(FEATURES, feature_support.sum(axis=0)):\n",
    "    print(f\"{feat}: Selected in {count}/{len(cv_results['estimator'])} folds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab040069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RF-RFECV Robust CV Performance ---\n",
      "AUC: 0.679 ± 0.092\n",
      "Accuracy: 0.617 ± 0.088\n",
      "F1: 0.629 ± 0.101\n",
      "Precision: 0.649 ± 0.106\n",
      "Recall: 0.630 ± 0.150\n",
      "BalancedAcc: 0.616 ± 0.088\n",
      "\n",
      "--- Random Forest Feature Selection Frequency ---\n",
      "Feature_ThetaAlpha_Global: Selected in 43/50 folds\n",
      "Feature_DeltaBeta_Global: Selected in 30/50 folds\n",
      "Feature_PLI_Beta_C3P3: Selected in 29/50 folds\n",
      "Feature_PLI_Beta_F3P4: Selected in 17/50 folds\n",
      "Feature_Network_FrontPost_Beta_PLI: Selected in 30/50 folds\n",
      "Feature_DPBF_Alpha: Selected in 17/50 folds\n",
      "Feature_HubPLI_Beta_Frontal: Selected in 47/50 folds\n",
      "Feature_HubPLI_Alpha_Posterior: Selected in 26/50 folds\n",
      "Feature_HubPLI_Beta_Posterior: Selected in 22/50 folds\n",
      "Feature_HubPLI_Beta_Delta: Selected in 40/50 folds\n",
      "Feature_Delta_CentralParietal_Abs: Selected in 29/50 folds\n",
      "Feature_Theta_F5_Abs: Selected in 27/50 folds\n",
      "Feature_Theta_Global_Abs: Selected in 49/50 folds\n",
      "Feature_Theta_Frontal_ROI_Abs: Selected in 48/50 folds\n",
      "Feature_ThetaAlpha_Peak_Freq: Selected in 27/50 folds\n",
      "Feature_Gamma_Posterior_Abs: Selected in 47/50 folds\n",
      "Feature_Theta_Asymmetry_Idx: Selected in 44/50 folds\n",
      "Feature_DWT_Theta_energy_var: Selected in 34/50 folds\n",
      "Feature_DWT_Theta_over_alpha_frac: Selected in 47/50 folds\n",
      "Feature_Theta_Temporal_Correlation: Selected in 38/50 folds\n",
      "Feature_Delta_Functional_Strength_Posterior: Selected in 30/50 folds\n",
      "Feature_Sync_Delta_ClassA_Frontal: Selected in 44/50 folds\n",
      "Feature_Sync_Theta_ClassD_Central: Selected in 30/50 folds\n",
      "Feature_Instab_Alpha_duration_Var: Selected in 32/50 folds\n",
      "Feature_Instab_Delta_duration_Var: Selected in 16/50 folds\n",
      "Feature_Instab_Theta_duration_Var: Selected in 18/50 folds\n",
      "Feature_Instab_Alpha_occurrence_Var: Selected in 14/50 folds\n",
      "Feature_Instab_Delta_occurrence_Var: Selected in 30/50 folds\n",
      "Feature_Instab_Theta_occurrence_Var: Selected in 23/50 folds\n",
      "Feature_Instab_Alpha_coverage_CV: Selected in 28/50 folds\n",
      "Feature_Instab_Delta_coverage_CV: Selected in 26/50 folds\n",
      "Feature_Instab_Theta_coverage_CV: Selected in 23/50 folds\n",
      "Feature_Theta_Asymmetry_Idx.1: Selected in 41/50 folds\n",
      "Feature_Theta_Asymmetry_Idx.2: Selected in 41/50 folds\n",
      "Feature_Theta_Asymmetry_Idx.3: Selected in 43/50 folds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\Documents\\EEG_Project\\dataSheets\\ML_Feature_Matrix.csv\")\n",
    "\n",
    "# Automatically select all features except ID/labels\n",
    "X = df.drop(columns=['participant_id', 'Target_MoCA', 'Label_Impaired']).values\n",
    "FEATURES = df.drop(columns=['participant_id', 'Target_MoCA', 'Label_Impaired']).columns\n",
    "y = df['Label_Impaired'].values\n",
    "\n",
    "# =========================\n",
    "# SCORING METRICS\n",
    "# =========================\n",
    "scoring_metrics = {\n",
    "    'AUC': 'roc_auc',\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': make_scorer(f1_score),\n",
    "    'Precision': make_scorer(precision_score, zero_division=0),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'BalancedAcc': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# BASE RF FOR RFECV\n",
    "# =========================\n",
    "selector_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# RFECV FEATURE SELECTOR\n",
    "# =========================\n",
    "rfecv = RFECV(\n",
    "    estimator=selector_rf,\n",
    "    step=1,\n",
    "    cv=StratifiedKFold(5, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    min_features_to_select=3,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# FULL PIPELINE\n",
    "# =========================\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selection', rfecv),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# REPEATED CV\n",
    "# =========================\n",
    "cv_robust = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    rf_pipeline, X, y,\n",
    "    cv=cv_robust,\n",
    "    scoring=scoring_metrics,\n",
    "    n_jobs=1,\n",
    "    return_estimator=True\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# REPORT METRICS\n",
    "# =========================\n",
    "print(\"\\n--- RF-RFECV Robust CV Performance ---\")\n",
    "for metric in scoring_metrics.keys():\n",
    "    scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric}: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "# =========================\n",
    "# FEATURE STABILITY\n",
    "# =========================\n",
    "feature_support = np.array([est.named_steps['feature_selection'].support_ for est in cv_results['estimator']])\n",
    "print(\"\\n--- Random Forest Feature Selection Frequency ---\")\n",
    "for feat, count in zip(FEATURES, feature_support.sum(axis=0)):\n",
    "    print(f\"{feat}: Selected in {count}/{len(cv_results['estimator'])} folds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a24fe60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RF 6-Feature Model CV Performance (Repeated 5x10) ---\n",
      "AUC: 0.739 ± 0.099\n",
      "Accuracy: 0.728 ± 0.084\n",
      "F1: 0.737 ± 0.096\n",
      "Precision: 0.752 ± 0.097\n",
      "Recall: 0.739 ± 0.142\n",
      "BalancedAcc: 0.727 ± 0.085\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-5.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-5.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=10, max_features=None,\n",
       "                       min_samples_split=5, n_estimators=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of trees in the forest.<br><br>.. versionchanged:: 0.22<br>   The default value of ``n_estimators`` changed from 10 to 100<br>   in 0.22.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">500</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.<br>Note: This parameter is tree-specific.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D%22sqrt%22\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. versionchanged:: 1.1<br>    The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=bootstrap,-bool%2C%20default%3DTrue\">\n",
       "            bootstrap\n",
       "            <span class=\"param-doc-description\">bootstrap: bool, default=True<br><br>Whether bootstrap samples are used when building trees. If False, the<br>whole dataset is used to build each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse\">\n",
       "            oob_score\n",
       "            <span class=\"param-doc-description\">oob_score: bool or callable, default=False<br><br>Whether to use out-of-bag samples to estimate the generalization score.<br>By default, :func:`~sklearn.metrics.accuracy_score` is used.<br>Provide a callable with signature `metric(y_true, y_pred)` to use a<br>custom metric. Only available if `bootstrap=True`.<br><br>For an illustration of out-of-bag (OOB) error estimation, see the example<br>:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>context. ``-1`` means using all processors. See :term:`Glossary<br><n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls both the randomness of the bootstrapping of the samples used<br>when building trees (if ``bootstrap=True``) and the sampling of the<br>features to consider when looking for the best split at each node<br>(if ``max_features < n_features``).<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Controls the verbosity when fitting and predicting.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just fit a whole<br>new forest. See :term:`Glossary <warm_start>` and<br>:ref:`tree_ensemble_warm_start` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=class_weight,-%7B%22balanced%22%2C%20%22balanced_subsample%22%7D%2C%20dict%20or%20list%20of%20dicts%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>The \"balanced_subsample\" mode is the same as \"balanced\" except that<br>weights are computed based on the bootstrap sample for every tree<br>grown.<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone\">\n",
       "            max_samples\n",
       "            <span class=\"param-doc-description\">max_samples: int or float, default=None<br><br>If bootstrap is True, the number of samples to draw from X<br>to train each base estimator.<br><br>- If None (default), then draw `X.shape[0]` samples.<br>- If int, then draw `max_samples` samples.<br>- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>  `max_samples` should be in the interval `(0.0, 1.0]`.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-5');</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=10, max_features=None,\n",
       "                       min_samples_split=5, n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, balanced_accuracy_score, roc_auc_score\n",
    "import joblib\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "df = pd.read_csv(\"ML_Feature_Matrix.csv\")\n",
    "\n",
    "FEATURES = [\n",
    "    'Feature_Sync_Delta_ClassA_Frontal',\n",
    "    'Feature_Theta_Global_Abs',\n",
    "    'Feature_HubPLI_Beta_Delta',\n",
    "    'Feature_DeltaBeta_Global',\n",
    "    'Feature_Theta_Asymmetry_Idx',\n",
    "    'Feature_ThetaAlpha_Global',\n",
    "]\n",
    "\n",
    "X = df[FEATURES].values\n",
    "y = df['Label_Impaired'].values\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "\n",
    "scoring_metrics = {\n",
    "    'AUC': 'roc_auc',\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': make_scorer(f1_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'BalancedAcc': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# RANDOM FOREST PIPELINE\n",
    "# =========================\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500,        # More trees for stability\n",
    "    max_depth=10,            # Limit depth to reduce overfitting\n",
    "    min_samples_split=5,     # Minimum samples per split\n",
    "    max_features=None,       # Use all features per tree\n",
    "    bootstrap=True,          # Standard RF bootstrap\n",
    "    class_weight='balanced', # Handle class imbalance\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# CROSS-VALIDATED EVALUATION\n",
    "# =========================\n",
    "cv_results = cross_validate(\n",
    "    rf, X, y,\n",
    "    cv=cv,\n",
    "    scoring=scoring_metrics,\n",
    "    return_train_score=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\n--- RF 6-Feature Model CV Performance (Repeated 5x10) ---\")\n",
    "for key, scores in cv_results.items():\n",
    "    if key.startswith('test_'):\n",
    "        print(f\"{key[5:]}: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "# =========================\n",
    "# TRAIN FINAL MODEL\n",
    "# =========================\n",
    "rf.fit(X, y)\n",
    "#joblib.dump(rf, \"PD_MoCA_RF_6Feature_Final.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede6056",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FEATURES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 1. DATA SPLITTING — 80/20, Test Set Locked Away\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     12\u001b[39m df = pd.read_csv(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUser\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEEG_Project\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdataSheets\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mML_Feature_Matrix.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m X = df[FEATURES].values\n\u001b[32m     14\u001b[39m y = df[\u001b[33m'\u001b[39m\u001b[33mLabel_Impaired\u001b[39m\u001b[33m'\u001b[39m].values\n\u001b[32m     15\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m     16\u001b[39m     X, y, test_size=\u001b[32m0.20\u001b[39m, stratify=y, random_state=RANDOM_STATE\n\u001b[32m     17\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'FEATURES' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "RANDOM_STATE   = 4223\n",
    "# ============================================================\n",
    "# 1. DATA SPLITTING — 80/20, Test Set Locked Away\n",
    "# ============================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Data Split: Train={len(X_train)} | Test={len(X_test)}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. FORWARD FEATURE SELECTION (CV on Train only)\n",
    "#    Uses 5-fold stratified CV instead of a single val set\n",
    "#    — much more stable estimates, no data wasted\n",
    "# ============================================================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "selected_idx = []\n",
    "remaining_idx = list(range(X.shape[1]))\n",
    "best_auc = 0.0\n",
    "\n",
    "print(\"\\n--- Running Forward Selection (5-Fold CV) ---\")\n",
    "\n",
    "for step in range(MAX_FEATURES):\n",
    "    step_results = []\n",
    "\n",
    "    for i in remaining_idx:\n",
    "        trial_idx = selected_idx + [i]\n",
    "\n",
    "        # Pipeline handles scaler + model inside each CV fold — no leakage\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", RandomForestClassifier(\n",
    "                n_estimators=300, max_depth=5,\n",
    "                class_weight=\"balanced\", random_state=RANDOM_STATE,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            pipe, X_train[:, trial_idx], y_train,\n",
    "            cv=cv, scoring=\"roc_auc\", n_jobs=-1\n",
    "        )\n",
    "        step_results.append((i, scores.mean()))\n",
    "\n",
    "    best_i, best_step_auc = max(step_results, key=lambda x: x[1])\n",
    "\n",
    "    if best_step_auc <= best_auc + 1e-4:\n",
    "        print(\"No further improvement — stopping.\")\n",
    "        break\n",
    "\n",
    "    selected_idx.append(best_i)\n",
    "    remaining_idx.remove(best_i)\n",
    "    best_auc = best_step_auc\n",
    "    print(f\"Step {step+1}: Added '{FEATURES[best_i]}' | CV AUC: {best_auc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. FINAL MODEL — Retrain on ALL train data, evaluate on test\n",
    "# ============================================================\n",
    "pipe_final = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=300, max_depth=5,\n",
    "        class_weight=\"balanced\", random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe_final.fit(X_train[:, selected_idx], y_train)\n",
    "\n",
    "final_probs = pipe_final.predict_proba(X_test[:, selected_idx])[:, 1]\n",
    "final_preds = pipe_final.predict(X_test[:, selected_idx])\n",
    "\n",
    "auc = roc_auc_score(y_test, final_probs)\n",
    "acc = accuracy_score(y_test, final_preds)\n",
    "f1  = f1_score(y_test, final_preds)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 45)\n",
    "print(f\"SELECTED FEATURES : {FEATURES[selected_idx].tolist()}\")\n",
    "print(f\"TEST AUC          : {auc:.4f}\")\n",
    "print(f\"TEST ACCURACY     : {acc:.4f}\")\n",
    "print(f\"TEST F1           : {f1:.4f}\")\n",
    "print(\"=\" * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7275400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split: Train=80 | Test=20\n",
      "\n",
      "--- Running Forward Selection (5-Fold CV) ---\n",
      "Step 1: Added 'Feature_HubPLI_Beta_Delta' | CV AUC: 0.6930\n",
      "Step 2: Added 'Feature_Theta_Global_Abs' | CV AUC: 0.7390\n",
      "Step 3: Added 'Feature_Theta_Asymmetry_Idx' | CV AUC: 0.7576\n",
      "No further improvement — stopping.\n",
      "\n",
      "=============================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     82\u001b[39m f1  = f1_score(y_test, final_preds)\n\u001b[32m     84\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m45\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSELECTED FEATURES : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFEATURES[selected_idx].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     86\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTEST AUC          : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTEST ACCURACY     : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "RANDOM_STATE   = 42\n",
    "# ============================================================\n",
    "# 1. DATA SPLITTING — 80/20, Test Set Locked Away\n",
    "# ============================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Data Split: Train={len(X_train)} | Test={len(X_test)}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. FORWARD FEATURE SELECTION (CV on Train only)\n",
    "#    Uses 5-fold stratified CV instead of a single val set\n",
    "#    — much more stable estimates, no data wasted\n",
    "# ============================================================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "selected_idx = []\n",
    "remaining_idx = list(range(X.shape[1]))\n",
    "best_auc = 0.0\n",
    "\n",
    "print(\"\\n--- Running Forward Selection (5-Fold CV) ---\")\n",
    "\n",
    "for step in range(MAX_FEATURES):\n",
    "    step_results = []\n",
    "\n",
    "    for i in remaining_idx:\n",
    "        trial_idx = selected_idx + [i]\n",
    "\n",
    "        # Pipeline handles scaler + model inside each CV fold — no leakage\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", RandomForestClassifier(\n",
    "                n_estimators=300, max_depth=5,\n",
    "                class_weight=\"balanced\", random_state=RANDOM_STATE,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            pipe, X_train[:, trial_idx], y_train,\n",
    "            cv=cv, scoring=\"roc_auc\", n_jobs=-1\n",
    "        )\n",
    "        step_results.append((i, scores.mean()))\n",
    "\n",
    "    best_i, best_step_auc = max(step_results, key=lambda x: x[1])\n",
    "\n",
    "    if best_step_auc <= best_auc + 1e-4:\n",
    "        print(\"No further improvement — stopping.\")\n",
    "        break\n",
    "\n",
    "    selected_idx.append(best_i)\n",
    "    remaining_idx.remove(best_i)\n",
    "    best_auc = best_step_auc\n",
    "    print(f\"Step {step+1}: Added '{FEATURES[best_i]}' | CV AUC: {best_auc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. FINAL MODEL — Retrain on ALL train data, evaluate on test\n",
    "# ============================================================\n",
    "pipe_final = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=300, max_depth=5,\n",
    "        class_weight=\"balanced\", random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe_final.fit(X_train[:, selected_idx], y_train)\n",
    "\n",
    "final_probs = pipe_final.predict_proba(X_test[:, selected_idx])[:, 1]\n",
    "final_preds = pipe_final.predict(X_test[:, selected_idx])\n",
    "\n",
    "auc = roc_auc_score(y_test, final_probs)\n",
    "acc = accuracy_score(y_test, final_preds)\n",
    "f1  = f1_score(y_test, final_preds)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 45)\n",
    "print(f\"SELECTED FEATURES : {FEATURES[selected_idx].tolist()}\")\n",
    "print(f\"TEST AUC          : {auc:.4f}\")\n",
    "print(f\"TEST ACCURACY     : {acc:.4f}\")\n",
    "print(f\"TEST F1           : {f1:.4f}\")\n",
    "print(\"=\" * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7e30cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split: Train=80 | Test=20\n",
      "\n",
      "--- Running Forward Selection (5-Fold CV) ---\n",
      "Step 1: Added 'Feature_Theta_Asymmetry_Idx' | CV AUC: 0.6096\n",
      "Step 2: Added 'Feature_Theta_Global_Abs' | CV AUC: 0.7293\n",
      "Step 3: Added 'Feature_HubPLI_Beta_Delta' | CV AUC: 0.7823\n",
      "No further improvement — stopping.\n",
      "\n",
      "=============================================\n",
      "SELECTED FEATURES : ['Feature_Theta_Asymmetry_Idx', 'Feature_Theta_Global_Abs', 'Feature_HubPLI_Beta_Delta']\n",
      "TEST AUC          : 0.6869\n",
      "TEST ACCURACY     : 0.6000\n",
      "TEST F1           : 0.6364\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "RANDOM_STATE = 000\n",
    "MAX_FEATURES = 5  # cap forward selection at 5\n",
    "\n",
    "# ============================================================\n",
    "# 1. DATA SPLITTING — 80/20\n",
    "# ============================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"Data Split: Train={len(X_train)} | Test={len(X_test)}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. FORWARD FEATURE SELECTION (Transparent Step-by-Step)\n",
    "# ============================================================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "selected_idx = []\n",
    "remaining_idx = list(range(X.shape[1]))\n",
    "best_auc = 0.0\n",
    "\n",
    "print(\"\\n--- Running Forward Selection (5-Fold CV) ---\")\n",
    "for step in range(MAX_FEATURES):\n",
    "    step_results = []\n",
    "\n",
    "    for i in remaining_idx:\n",
    "        trial_idx = selected_idx + [i]\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", RandomForestClassifier(\n",
    "                n_estimators=300,\n",
    "                max_depth=5,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=4,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            pipe, X_train[:, trial_idx], y_train,\n",
    "            cv=cv, scoring=\"roc_auc\", n_jobs=-1\n",
    "        )\n",
    "        step_results.append((i, scores.mean()))\n",
    "\n",
    "    best_i, best_step_auc = max(step_results, key=lambda x: x[1])\n",
    "\n",
    "    # stop if no improvement\n",
    "    if best_step_auc <= best_auc + 1e-4:\n",
    "        print(\"No further improvement — stopping.\")\n",
    "        break\n",
    "\n",
    "    selected_idx.append(best_i)\n",
    "    remaining_idx.remove(best_i)\n",
    "    best_auc = best_step_auc\n",
    "    print(f\"Step {step+1}: Added '{FEATURES[best_i]}' | CV AUC: {best_auc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. FINAL MODEL\n",
    "# ============================================================\n",
    "pipe_final = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe_final.fit(X_train[:, selected_idx], y_train)\n",
    "final_probs = pipe_final.predict_proba(X_test[:, selected_idx])[:, 1]\n",
    "final_preds = pipe_final.predict(X_test[:, selected_idx])\n",
    "\n",
    "auc = roc_auc_score(y_test, final_probs)\n",
    "acc = accuracy_score(y_test, final_preds)\n",
    "f1  = f1_score(y_test, final_preds)\n",
    "\n",
    "print(\"\\n\" + \"=\"*45)\n",
    "print(f\"SELECTED FEATURES : {[FEATURES[i] for i in selected_idx]}\")\n",
    "print(f\"TEST AUC          : {auc:.4f}\")\n",
    "print(f\"TEST ACCURACY     : {acc:.4f}\")\n",
    "print(f\"TEST F1           : {f1:.4f}\")\n",
    "print(\"=\"*45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
