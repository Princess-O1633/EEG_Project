{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa08a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final 6-Feature Model CV Performance ---\n",
      "test_AUC: 0.767 ± 0.099\n",
      "test_Accuracy: 0.730 ± 0.040\n",
      "test_F1: 0.732 ± 0.063\n",
      "test_Precision: 0.769 ± 0.063\n",
      "test_Recall: 0.715 ± 0.113\n",
      "test_BalancedAcc: 0.729 ± 0.040\n",
      "\n",
      "--- Feature Importances ---\n",
      "Feature_Theta_Global_Abs             0.250293\n",
      "Feature_Theta_Asymmetry_Idx          0.201214\n",
      "Feature_Sync_Delta_ClassA_Frontal    0.178198\n",
      "Feature_HubPLI_Beta_Delta            0.150434\n",
      "Feature_DeltaBeta_Global             0.134646\n",
      "Feature_Instab_Theta_duration_Var    0.085216\n",
      "dtype: float64\n",
      "\n",
      "Final model saved as PD_MoCA_RF_6Feature_Final.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import joblib\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "df = pd.read_csv(\"ML_Feature_Matrix.csv\")\n",
    "\n",
    "# Define the 6 features from forward selection\n",
    "FEATURES = [\n",
    "    'Feature_Sync_Delta_ClassA_Frontal',\n",
    "    'Feature_Theta_Global_Abs',\n",
    "    'Feature_HubPLI_Beta_Delta',\n",
    "    'Feature_DeltaBeta_Global',\n",
    "    'Feature_Theta_Asymmetry_Idx',\n",
    "    'Feature_Instab_Theta_duration_Var'\n",
    "]\n",
    "\n",
    "X = df[FEATURES].values\n",
    "y = df['Label_Impaired'].values\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring_metrics = {\n",
    "    'AUC': 'roc_auc',\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': make_scorer(f1_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'BalancedAcc': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# BUILD FINAL MODEL PIPELINE\n",
    "# =========================\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=800,\n",
    "        max_depth=6,\n",
    "        min_samples_leaf=4,\n",
    "        min_samples_split=8,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# CROSS-VALIDATED EVALUATION\n",
    "# =========================\n",
    "cv_results = cross_validate(final_pipeline, X, y, cv=cv, scoring=scoring_metrics, return_train_score=False)\n",
    "\n",
    "print(\"\\n--- Final 6-Feature Model CV Performance ---\")\n",
    "for metric_name, scores in cv_results.items():\n",
    "    if metric_name.startswith('test_'):\n",
    "        print(f\"{metric_name}: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "# =========================\n",
    "# TRAIN FINAL MODEL ON FULL DATA\n",
    "# =========================\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# =========================\n",
    "# FEATURE IMPORTANCE EXTRACTION\n",
    "# =========================\n",
    "rf_model = final_pipeline.named_steps['rf']\n",
    "importances = pd.Series(rf_model.feature_importances_, index=FEATURES).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n--- Feature Importances ---\")\n",
    "print(importances)\n",
    "\n",
    "# =========================\n",
    "# SAVE MODEL\n",
    "# =========================\n",
    "joblib.dump(final_pipeline, \"PD_MoCA_RF_6Feature_Final.pkl\")\n",
    "print(\"\\nFinal model saved as PD_MoCA_RF_6Feature_Final.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d18a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CV Performance ---\n",
      "test_AUC: 0.767 ± 0.099\n",
      "test_Accuracy: 0.730 ± 0.040\n",
      "test_F1: 0.732 ± 0.063\n",
      "test_Precision: 0.769 ± 0.063\n",
      "test_Recall: 0.715 ± 0.113\n",
      "test_BalancedAcc: 0.729 ± 0.040\n",
      "\n",
      "Sample continuous cognitive risk scores:\n",
      "  participant_id  MoCA_Risk_Score\n",
      "0        sub-001         0.503580\n",
      "1        sub-002         0.862633\n",
      "2        sub-003         0.585766\n",
      "3        sub-004         0.702518\n",
      "4        sub-005         0.806243\n",
      "\n",
      "--- Feature Importances ---\n",
      "Feature_Theta_Global_Abs             0.250293\n",
      "Feature_Theta_Asymmetry_Idx          0.201214\n",
      "Feature_Sync_Delta_ClassA_Frontal    0.178198\n",
      "Feature_HubPLI_Beta_Delta            0.150434\n",
      "Feature_DeltaBeta_Global             0.134646\n",
      "Feature_Instab_Theta_duration_Var    0.085216\n",
      "dtype: float64\n",
      "\n",
      "Final model saved as PD_MoCA_RF_6Feature_RiskScore.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, f1_score, accuracy_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import joblib\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "df = pd.read_csv(\"ML_Feature_Matrix.csv\")\n",
    "\n",
    "# Use your 6 selected features\n",
    "FEATURES = [\n",
    "    'Feature_Sync_Delta_ClassA_Frontal',\n",
    "    'Feature_Theta_Global_Abs',\n",
    "    'Feature_HubPLI_Beta_Delta',\n",
    "    'Feature_DeltaBeta_Global',\n",
    "    'Feature_Theta_Asymmetry_Idx',\n",
    "    'Feature_Instab_Theta_duration_Var'\n",
    "]\n",
    "\n",
    "X = df[FEATURES].values\n",
    "y = df['Label_Impaired'].values  # binary target\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring_metrics = {\n",
    "    'AUC': 'roc_auc',\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': make_scorer(f1_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'BalancedAcc': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# BUILD PIPELINE\n",
    "# =========================\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=800,\n",
    "        max_depth=6,\n",
    "        min_samples_leaf=4,\n",
    "        min_samples_split=8,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# CROSS-VALIDATED EVALUATION\n",
    "# =========================\n",
    "cv_results = cross_validate(rf_pipeline, X, y, cv=cv, scoring=scoring_metrics, return_train_score=False)\n",
    "\n",
    "print(\"\\n--- CV Performance ---\")\n",
    "for metric_name, scores in cv_results.items():\n",
    "    if metric_name.startswith('test_'):\n",
    "        print(f\"{metric_name}: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "# =========================\n",
    "# TRAIN FINAL MODEL ON FULL DATA\n",
    "# =========================\n",
    "rf_pipeline.fit(X, y)\n",
    "\n",
    "# =========================\n",
    "# CONTINUOUS RISK SCORE\n",
    "# =========================\n",
    "# This is the probability of being impaired (continuous 0–1)\n",
    "risk_scores = rf_pipeline.predict_proba(X)[:, 1]\n",
    "df['MoCA_Risk_Score'] = risk_scores\n",
    "print(\"\\nSample continuous cognitive risk scores:\")\n",
    "print(df[['participant_id', 'MoCA_Risk_Score']].head())\n",
    "\n",
    "# =========================\n",
    "# FEATURE IMPORTANCES\n",
    "# =========================\n",
    "rf_model = rf_pipeline.named_steps['rf']\n",
    "importances = pd.Series(rf_model.feature_importances_, index=FEATURES).sort_values(ascending=False)\n",
    "print(\"\\n--- Feature Importances ---\")\n",
    "print(importances)\n",
    "\n",
    "# =========================\n",
    "# SAVE MODEL\n",
    "# =========================\n",
    "joblib.dump(rf_pipeline, \"PD_MoCA_RF_6Feature_RiskScore.pkl\")\n",
    "print(\"\\nFinal model saved as PD_MoCA_RF_6Feature_RiskScore.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624b324",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf7343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     49\u001b[39m cv = StratifiedKFold(n_splits=\u001b[32m5\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     51\u001b[39m search = RandomizedSearchCV(\n\u001b[32m     52\u001b[39m     rf_pipeline, \n\u001b[32m     53\u001b[39m     param_distributions=param_dist, \n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     60\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m search.fit(X, y)\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Best Hyperparameters ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(search.best_params_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\eeg_ml\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\eeg_ml\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1053\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1047\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1048\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1049\u001b[39m     )\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m \u001b[38;5;28mself\u001b[39m._run_search(evaluate_candidates)\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1057\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\eeg_ml\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:2002\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   2000\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   2001\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2002\u001b[39m     evaluate_candidates(\n\u001b[32m   2003\u001b[39m         ParameterSampler(\n\u001b[32m   2004\u001b[39m             \u001b[38;5;28mself\u001b[39m.param_distributions, \u001b[38;5;28mself\u001b[39m.n_iter, random_state=\u001b[38;5;28mself\u001b[39m.random_state\n\u001b[32m   2005\u001b[39m         )\n\u001b[32m   2006\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\eeg_ml\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:999\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    992\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    993\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    994\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    995\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    996\u001b[39m         )\n\u001b[32m    997\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m999\u001b[39m out = parallel(\n\u001b[32m   1000\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m   1001\u001b[39m         clone(base_estimator),\n\u001b[32m   1002\u001b[39m         X,\n\u001b[32m   1003\u001b[39m         y,\n\u001b[32m   1004\u001b[39m         train=train,\n\u001b[32m   1005\u001b[39m         test=test,\n\u001b[32m   1006\u001b[39m         parameters=parameters,\n\u001b[32m   1007\u001b[39m         split_progress=(split_idx, n_splits),\n\u001b[32m   1008\u001b[39m         candidate_progress=(cand_idx, n_candidates),\n\u001b[32m   1009\u001b[39m         **fit_and_score_kwargs,\n\u001b[32m   1010\u001b[39m     )\n\u001b[32m   1011\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[32m   1012\u001b[39m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[32m   1013\u001b[39m         \u001b[38;5;28menumerate\u001b[39m(cv.split(X, y, **routed_params.splitter.split)),\n\u001b[32m   1014\u001b[39m     )\n\u001b[32m   1015\u001b[39m )\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1021\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1022\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\eeg_ml\\Lib\\site-packages\\sklearn\\utils\\parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(iterable_with_config_and_warning_filters)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\eeg_ml\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\eeg_ml\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\eeg_ml\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, precision_score, recall_score, balanced_accuracy_score, roc_auc_score\n",
    "import joblib\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "df = pd.read_csv(\"ML_Feature_Matrix.csv\")\n",
    "\n",
    "FEATURES = [\n",
    "    'Feature_Sync_Delta_ClassA_Frontal',\n",
    "    'Feature_Theta_Global_Abs',\n",
    "    'Feature_HubPLI_Beta_Delta',\n",
    "    'Feature_DeltaBeta_Global',\n",
    "    'Feature_Theta_Asymmetry_Idx',\n",
    "    'Feature_Instab_Theta_duration_Var'\n",
    "]\n",
    "\n",
    "X = df[FEATURES].values\n",
    "y = df['Label_Impaired'].values\n",
    "\n",
    "# =========================\n",
    "# PIPELINE\n",
    "# =========================\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# HYPERPARAMETER SPACE\n",
    "# =========================\n",
    "param_dist = {\n",
    "    'rf__n_estimators': [500, 800, 1000, 1200],\n",
    "    'rf__max_depth': [4, 6, 8, 10, None],\n",
    "    'rf__min_samples_leaf': [2, 4, 6, 8],\n",
    "    'rf__min_samples_split': [2, 4, 6, 8],\n",
    "    'rf__max_features': ['sqrt', 'log2', 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# CROSS-VALIDATION & RANDOM SEARCH\n",
    "# =========================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    rf_pipeline, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=30, \n",
    "    cv=cv, \n",
    "    scoring='roc_auc', \n",
    "    n_jobs=-1, \n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(X, y)\n",
    "\n",
    "print(\"\\n=== Best Hyperparameters ===\")\n",
    "print(search.best_params_)\n",
    "print(f\"Best CV AUC: {search.best_score_:.3f}\")\n",
    "\n",
    "# =========================\n",
    "# EVALUATE CV METRICS\n",
    "# =========================\n",
    "best_model = search.best_estimator_\n",
    "\n",
    "# Use cross_validate to report multiple metrics\n",
    "scoring_metrics = {\n",
    "    'AUC': 'roc_auc',\n",
    "    'Accuracy': 'accuracy',\n",
    "    'F1': make_scorer(f1_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'BalancedAcc': make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "\n",
    "cv_results = cross_validate(best_model, X, y, cv=cv, scoring=scoring_metrics, return_train_score=False)\n",
    "\n",
    "print(\"\\n--- Optimized CV Performance ---\")\n",
    "for metric_name, scores in cv_results.items():\n",
    "    if metric_name.startswith('test_'):\n",
    "        print(f\"{metric_name}: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "# =========================\n",
    "# TRAIN FINAL MODEL ON FULL DATA\n",
    "# =========================\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# =========================\n",
    "# CONTINUOUS RISK SCORE\n",
    "# =========================\n",
    "risk_scores = best_model.predict_proba(X)[:, 1]\n",
    "df['MoCA_Risk_Score'] = risk_scores\n",
    "print(\"\\nSample continuous cognitive risk scores:\")\n",
    "print(df[['participant_id', 'MoCA_Risk_Score']].tail())\n",
    "\n",
    "# =========================\n",
    "# FEATURE IMPORTANCES\n",
    "# =========================\n",
    "rf_model = best_model.named_steps['rf']\n",
    "importances = pd.Series(rf_model.feature_importances_, index=FEATURES).sort_values(ascending=False)\n",
    "print(\"\\n--- Feature Importances ---\")\n",
    "print(importances)\n",
    "\n",
    "# =========================\n",
    "# SAVE FINAL MODEL\n",
    "# =========================\n",
    "joblib.dump(best_model, \"PD_MoCA_RF_6Feature_Optimized.pkl\")\n",
    "print(\"\\nFinal optimized model saved as PD_MoCA_RF_6Feature_Optimized.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
